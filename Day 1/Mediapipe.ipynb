{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naveed/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libEGL warning: failed to get driver name for fd -1\n",
      "\n",
      "libEGL warning: MESA-LOADER: failed to retrieve device information\n",
      "\n",
      "libEGL warning: failed to get driver name for fd -1\n",
      "\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725366483.053331   99424 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1725366483.058044  127149 gl_context.cc:357] GL version: 3.2 (OpenGL ES 3.2 Mesa 23.2.1-1ubuntu3.1~22.04.2), renderer: Mesa Intel(R) UHD Graphics (CML GT2)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1725366483.273522  127137 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1725366483.325304  127138 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naveed/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 35 persons, 2 birds, 324.4ms\n",
      "Speed: 9.2ms preprocess, 324.4ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naveed/.local/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 34 persons, 3 birds, 236.3ms\n",
      "Speed: 3.3ms preprocess, 236.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 persons, 3 birds, 150.4ms\n",
      "Speed: 4.3ms preprocess, 150.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 persons, 2 birds, 162.7ms\n",
      "Speed: 2.7ms preprocess, 162.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 persons, 2 birds, 146.2ms\n",
      "Speed: 2.5ms preprocess, 146.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 persons, 2 birds, 158.0ms\n",
      "Speed: 3.2ms preprocess, 158.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 persons, 3 birds, 143.6ms\n",
      "Speed: 2.9ms preprocess, 143.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 persons, 2 birds, 156.1ms\n",
      "Speed: 2.6ms preprocess, 156.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 persons, 2 birds, 142.1ms\n",
      "Speed: 3.2ms preprocess, 142.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 persons, 2 birds, 148.2ms\n",
      "Speed: 2.5ms preprocess, 148.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 2 birds, 147.7ms\n",
      "Speed: 2.8ms preprocess, 147.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 persons, 2 birds, 141.1ms\n",
      "Speed: 2.9ms preprocess, 141.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 2 birds, 139.4ms\n",
      "Speed: 3.7ms preprocess, 139.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 persons, 3 birds, 143.1ms\n",
      "Speed: 3.5ms preprocess, 143.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 4 birds, 170.4ms\n",
      "Speed: 2.9ms preprocess, 170.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 persons, 4 birds, 175.8ms\n",
      "Speed: 4.1ms preprocess, 175.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 3 birds, 162.3ms\n",
      "Speed: 3.5ms preprocess, 162.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 2 birds, 143.7ms\n",
      "Speed: 3.1ms preprocess, 143.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 persons, 2 birds, 158.2ms\n",
      "Speed: 2.8ms preprocess, 158.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 persons, 2 birds, 143.5ms\n",
      "Speed: 2.9ms preprocess, 143.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 persons, 2 birds, 1 dog, 162.8ms\n",
      "Speed: 2.8ms preprocess, 162.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 1 bird, 1 dog, 143.8ms\n",
      "Speed: 3.2ms preprocess, 143.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 persons, 1 bird, 1 dog, 137.6ms\n",
      "Speed: 3.5ms preprocess, 137.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 1 bird, 1 dog, 142.0ms\n",
      "Speed: 3.9ms preprocess, 142.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 1 bird, 1 dog, 144.4ms\n",
      "Speed: 3.1ms preprocess, 144.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 1 bird, 1 dog, 159.1ms\n",
      "Speed: 4.7ms preprocess, 159.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 persons, 1 bird, 140.8ms\n",
      "Speed: 3.6ms preprocess, 140.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 persons, 1 bird, 159.2ms\n",
      "Speed: 3.1ms preprocess, 159.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 persons, 1 bird, 146.7ms\n",
      "Speed: 3.5ms preprocess, 146.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 persons, 1 bird, 157.5ms\n",
      "Speed: 4.0ms preprocess, 157.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 persons, 1 bird, 142.8ms\n",
      "Speed: 4.5ms preprocess, 142.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 persons, 2 birds, 136.7ms\n",
      "Speed: 3.2ms preprocess, 136.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 persons, 2 birds, 150.6ms\n",
      "Speed: 3.6ms preprocess, 150.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 1 bird, 143.8ms\n",
      "Speed: 2.6ms preprocess, 143.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 31 persons, 2 birds, 161.5ms\n",
      "Speed: 2.6ms preprocess, 161.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 1 bird, 140.1ms\n",
      "Speed: 3.1ms preprocess, 140.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 persons, 1 bird, 173.3ms\n",
      "Speed: 3.4ms preprocess, 173.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 persons, 2 birds, 146.1ms\n",
      "Speed: 2.6ms preprocess, 146.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 persons, 1 bird, 161.4ms\n",
      "Speed: 2.9ms preprocess, 161.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 persons, 2 birds, 145.3ms\n",
      "Speed: 3.9ms preprocess, 145.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 32 persons, 2 birds, 147.5ms\n",
      "Speed: 3.1ms preprocess, 147.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 34 persons, 2 birds, 156.9ms\n",
      "Speed: 3.2ms preprocess, 156.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 33 persons, 2 birds, 141.6ms\n",
      "Speed: 2.5ms preprocess, 141.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 persons, 2 birds, 148.0ms\n",
      "Speed: 3.3ms preprocess, 148.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 35 persons, 2 birds, 144.2ms\n",
      "Speed: 3.0ms preprocess, 144.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 persons, 2 birds, 160.9ms\n",
      "Speed: 3.2ms preprocess, 160.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 persons, 1 bird, 146.9ms\n",
      "Speed: 2.5ms preprocess, 146.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 36 persons, 1 bird, 156.6ms\n",
      "Speed: 3.1ms preprocess, 156.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 persons, 1 bird, 1 dog, 134.9ms\n",
      "Speed: 3.3ms preprocess, 134.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 38 persons, 1 bird, 1 dog, 157.8ms\n",
      "Speed: 4.0ms preprocess, 157.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 41 persons, 1 bird, 1 dog, 154.0ms\n",
      "Speed: 2.7ms preprocess, 154.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 40 persons, 1 bird, 1 dog, 162.9ms\n",
      "Speed: 3.6ms preprocess, 162.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 37 persons, 1 bird, 1 dog, 147.8ms\n",
      "Speed: 2.8ms preprocess, 147.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize YOLOv8n model (pre-trained)\n",
    "yolo_model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Initialize MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Open video capture (replace 'path_to_video.mp4' with the actual video file path)\n",
    "video_path = 'Test.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLOv8n Detection\n",
    "    results = yolo_model(frame)\n",
    "    detections = results[0].boxes.xyxy  # Bounding boxes in xyxy format\n",
    "\n",
    "    # Loop through detections\n",
    "    for box in detections:\n",
    "        x1, y1, x2, y2 = map(int, box)  # Convert to integer\n",
    "\n",
    "        # Crop detected patient region\n",
    "        patient_region = frame[y1:y2, x1:x2]\n",
    "\n",
    "        # Convert patient region to RGB format for MediaPipe\n",
    "        rgb_patient = cv2.cvtColor(patient_region, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # MediaPipe Pose Estimation\n",
    "        result = pose.process(rgb_patient)\n",
    "\n",
    "        # Draw pose landmarks if detected\n",
    "        if result.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(patient_region, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        # Put the cropped region back in the original frame\n",
    "        frame[y1:y2, x1:x2] = patient_region\n",
    "\n",
    "    # Display the output frame\n",
    "    cv2.imshow('Patient Detection and Pose Estimation', frame)\n",
    "\n",
    "    # Break loop with 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "pose.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
