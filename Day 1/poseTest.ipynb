{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'human-pose-estimation-opencv'...\n",
      "remote: Enumerating objects: 20, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 20 (delta 5), reused 5 (delta 5), pack-reused 12 (from 1)\u001b[K\n",
      "Receiving objects: 100% (20/20), 10.09 MiB | 7.76 MiB/s, done.\n",
      "Resolving deltas: 100% (5/5), done.\n",
      "/home/naveed/Documents/Nexpred Solutions/Month4_September/Week 1/Day 1/human-pose-estimation-opencv/human-pose-estimation-opencv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naveed/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/misbah4064/human-pose-estimation-opencv.git\n",
    "%cd human-pose-estimation-opencv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "BODY_PARTS = { \"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "               \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "               \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
    "               \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18 }\n",
    "\n",
    "POSE_PAIRS = [ [\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "               [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "               [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "               [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
    "               [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"] ]\n",
    "\n",
    "width = 368\n",
    "height = 368\n",
    "inWidth = width\n",
    "inHeight = height\n",
    "\n",
    "net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
    "thr = 0.2\n",
    "\n",
    "def poseDetector(frame):\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    \n",
    "    net.setInput(cv.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "    out = net.forward()\n",
    "    out = out[:, :19, :, :]  # MobileNet output [1, 57, -1, -1], we only need the first 19 elements\n",
    "\n",
    "    assert(len(BODY_PARTS) == out.shape[1])\n",
    "\n",
    "    points = []\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "        # Slice heatmap of corresponging body's part.\n",
    "        heatMap = out[0, i, :, :]\n",
    "\n",
    "        _, conf, _, point = cv.minMaxLoc(heatMap)\n",
    "        x = (frameWidth * point[0]) / out.shape[3]\n",
    "        y = (frameHeight * point[1]) / out.shape[2]\n",
    "        points.append((int(x), int(y)) if conf > thr else None)\n",
    "\n",
    "    for pair in POSE_PAIRS:\n",
    "        partFrom = pair[0]\n",
    "        partTo = pair[1]\n",
    "        assert(partFrom in BODY_PARTS)\n",
    "        assert(partTo in BODY_PARTS)\n",
    "\n",
    "        idFrom = BODY_PARTS[partFrom]\n",
    "        idTo = BODY_PARTS[partTo]\n",
    "\n",
    "        if points[idFrom] and points[idTo]:\n",
    "            cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
    "            cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "            cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "\n",
    "    t, _ = net.getPerfProfile()\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Video...\n",
      "Done processing video\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('Test.mp4')\n",
    "ret, frame = cap.read()\n",
    "frame_height, frame_width, _ = frame.shape\n",
    "out = cv2.VideoWriter('output.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "print(\"Processing Video...\")\n",
    "while cap.isOpened():\n",
    "  ret, frame = cap.read()\n",
    "  if not ret:\n",
    "    out.release()\n",
    "    break\n",
    "  output = poseDetector(frame)\n",
    "  out.write(output)\n",
    "out.release()\n",
    "print(\"Done processing video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing on pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenPose model loaded successfully.\n",
      "Video file loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 35 persons, 2 birds, 113.9ms\n",
      "Speed: 3.5ms preprocess, 113.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 5390 milliseconds\n",
      "\n",
      "0: 384x640 34 persons, 3 birds, 109.3ms\n",
      "Speed: 2.2ms preprocess, 109.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 1848 milliseconds\n",
      "\n",
      "0: 384x640 35 persons, 3 birds, 105.9ms\n",
      "Speed: 2.1ms preprocess, 105.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 8444 milliseconds\n",
      "\n",
      "0: 384x640 36 persons, 2 birds, 105.6ms\n",
      "Speed: 3.4ms preprocess, 105.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 8836 milliseconds\n",
      "\n",
      "0: 384x640 37 persons, 2 birds, 128.0ms\n",
      "Speed: 2.1ms preprocess, 128.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 8813 milliseconds\n",
      "\n",
      "0: 384x640 37 persons, 2 birds, 109.3ms\n",
      "Speed: 2.3ms preprocess, 109.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9207 milliseconds\n",
      "\n",
      "0: 384x640 35 persons, 3 birds, 108.8ms\n",
      "Speed: 2.2ms preprocess, 108.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9098 milliseconds\n",
      "\n",
      "0: 384x640 35 persons, 2 birds, 107.8ms\n",
      "Speed: 2.2ms preprocess, 107.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9263 milliseconds\n",
      "\n",
      "0: 384x640 34 persons, 2 birds, 104.8ms\n",
      "Speed: 2.5ms preprocess, 104.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9188 milliseconds\n",
      "\n",
      "0: 384x640 36 persons, 2 birds, 103.2ms\n",
      "Speed: 3.6ms preprocess, 103.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9256 milliseconds\n",
      "\n",
      "0: 384x640 33 persons, 2 birds, 107.0ms\n",
      "Speed: 2.1ms preprocess, 107.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9142 milliseconds\n",
      "\n",
      "0: 384x640 34 persons, 2 birds, 99.8ms\n",
      "Speed: 2.6ms preprocess, 99.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9276 milliseconds\n",
      "\n",
      "0: 384x640 33 persons, 2 birds, 108.9ms\n",
      "Speed: 2.6ms preprocess, 108.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9183 milliseconds\n",
      "\n",
      "0: 384x640 34 persons, 3 birds, 106.0ms\n",
      "Speed: 2.2ms preprocess, 106.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9198 milliseconds\n",
      "\n",
      "0: 384x640 33 persons, 4 birds, 105.1ms\n",
      "Speed: 3.0ms preprocess, 105.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9536 milliseconds\n",
      "\n",
      "0: 384x640 34 persons, 4 birds, 116.2ms\n",
      "Speed: 2.2ms preprocess, 116.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9666 milliseconds\n",
      "\n",
      "0: 384x640 33 persons, 3 birds, 110.8ms\n",
      "Speed: 3.0ms preprocess, 110.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9937 milliseconds\n",
      "\n",
      "0: 384x640 33 persons, 2 birds, 102.2ms\n",
      "Speed: 2.1ms preprocess, 102.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9227 milliseconds\n",
      "\n",
      "0: 384x640 32 persons, 2 birds, 97.6ms\n",
      "Speed: 2.1ms preprocess, 97.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9103 milliseconds\n",
      "\n",
      "0: 384x640 34 persons, 2 birds, 100.9ms\n",
      "Speed: 2.6ms preprocess, 100.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 10811 milliseconds\n",
      "\n",
      "0: 384x640 31 persons, 2 birds, 1 dog, 107.3ms\n",
      "Speed: 2.4ms preprocess, 107.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 10968 milliseconds\n",
      "\n",
      "0: 384x640 33 persons, 1 bird, 1 dog, 104.0ms\n",
      "Speed: 3.1ms preprocess, 104.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Time to process 1 frame: 9628 milliseconds\n",
      "\n",
      "0: 384x640 32 persons, 1 bird, 1 dog, 104.2ms\n",
      "Speed: 2.7ms preprocess, 104.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:798: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 116\u001b[0m\n\u001b[1;32m    114\u001b[0m cropped_image \u001b[38;5;241m=\u001b[39m frame[ymin:ymax, xmin:xmax]\n\u001b[1;32m    115\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtracked_images/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrack_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 116\u001b[0m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtracked_images/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtrack_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/frame_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimestamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcropped_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Perform pose estimation\u001b[39;00m\n\u001b[1;32m    119\u001b[0m pose_frame \u001b[38;5;241m=\u001b[39m poseDetector(cropped_image)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:798: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import os\n",
    "\n",
    "# YOLO model and DeepSort initialization\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "tracker = DeepSort(max_age=50)\n",
    "\n",
    "# Body parts and pose pairs for OpenPose\n",
    "BODY_PARTS = {\"Nose\": 0, \"Neck\": 1, \"RShoulder\": 2, \"RElbow\": 3, \"RWrist\": 4,\n",
    "              \"LShoulder\": 5, \"LElbow\": 6, \"LWrist\": 7, \"RHip\": 8, \"RKnee\": 9,\n",
    "              \"RAnkle\": 10, \"LHip\": 11, \"LKnee\": 12, \"LAnkle\": 13, \"REye\": 14,\n",
    "              \"LEye\": 15, \"REar\": 16, \"LEar\": 17, \"Background\": 18}\n",
    "\n",
    "POSE_PAIRS = [[\"Neck\", \"RShoulder\"], [\"Neck\", \"LShoulder\"], [\"RShoulder\", \"RElbow\"],\n",
    "              [\"RElbow\", \"RWrist\"], [\"LShoulder\", \"LElbow\"], [\"LElbow\", \"LWrist\"],\n",
    "              [\"Neck\", \"RHip\"], [\"RHip\", \"RKnee\"], [\"RKnee\", \"RAnkle\"], [\"Neck\", \"LHip\"],\n",
    "              [\"LHip\", \"LKnee\"], [\"LKnee\", \"LAnkle\"], [\"Neck\", \"Nose\"], [\"Nose\", \"REye\"],\n",
    "              [\"REye\", \"REar\"], [\"Nose\", \"LEye\"], [\"LEye\", \"LEar\"]]\n",
    "\n",
    "# Load OpenPose model\n",
    "try:\n",
    "    net = cv.dnn.readNetFromTensorflow(\"graph_opt.pb\")\n",
    "    print(\"OpenPose model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load OpenPose model:\", e)\n",
    "\n",
    "inWidth, inHeight = 368, 368\n",
    "thr = 0.2\n",
    "\n",
    "def poseDetector(frame):\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    net.setInput(cv.dnn.blobFromImage(frame, 1.0, (inWidth, inHeight), (127.5, 127.5, 127.5), swapRB=True, crop=False))\n",
    "    out = net.forward()\n",
    "    out = out[:, :19, :, :]  # Only need the first 19 elements for pose\n",
    "\n",
    "    points = []\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "        heatMap = out[0, i, :, :]\n",
    "        _, conf, _, point = cv.minMaxLoc(heatMap)\n",
    "        x = (frameWidth * point[0]) / out.shape[3]\n",
    "        y = (frameHeight * point[1]) / out.shape[2]\n",
    "        points.append((int(x), int(y)) if conf > thr else None)\n",
    "\n",
    "    for pair in POSE_PAIRS:\n",
    "        partFrom = pair[0]\n",
    "        partTo = pair[1]\n",
    "        idFrom = BODY_PARTS[partFrom]\n",
    "        idTo = BODY_PARTS[partTo]\n",
    "\n",
    "        if points[idFrom] and points[idTo]:\n",
    "            cv.line(frame, points[idFrom], points[idTo], (0, 255, 0), 3)\n",
    "            cv.ellipse(frame, points[idFrom], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "            cv.ellipse(frame, points[idTo], (3, 3), 0, 0, 360, (0, 0, 255), cv.FILLED)\n",
    "\n",
    "    return frame\n",
    "\n",
    "def create_video_writer(video_cap, output_filename):\n",
    "    frame_width = int(video_cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(video_cap.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video_cap.get(cv.CAP_PROP_FPS))\n",
    "    fourcc = cv.VideoWriter_fourcc(*'MP4V')\n",
    "    writer = cv.VideoWriter(output_filename, fourcc, fps, (frame_width, frame_height))\n",
    "    return writer\n",
    "\n",
    "# Initialize video capture and writer\n",
    "video_cap = cv.VideoCapture(\"Test.mp4\")\n",
    "if not video_cap.isOpened():\n",
    "    print(\"Error: Unable to open video file.\")\n",
    "else:\n",
    "    print(\"Video file loaded successfully.\")\n",
    "\n",
    "writer = create_video_writer(video_cap, \"Testoutput1.mp4\")\n",
    "\n",
    "while True:\n",
    "    start = datetime.datetime.now()\n",
    "    ret, frame = video_cap.read()\n",
    "    if not ret:\n",
    "        print(\"No more frames to read or video file error.\")\n",
    "        break\n",
    "\n",
    "    # Run YOLO model for detection\n",
    "    detections = model(frame)[0]\n",
    "\n",
    "    if detections is None or len(detections) == 0:\n",
    "        print(\"No detections from YOLO.\")\n",
    "        continue\n",
    "\n",
    "    results = []\n",
    "    for data in detections.boxes.data.tolist():\n",
    "        confidence = data[4]\n",
    "        if float(confidence) < 0.2:\n",
    "            continue\n",
    "        xmin, ymin, xmax, ymax = int(data[0]), int(data[1]), int(data[2]), int(data[3])\n",
    "        class_id = int(data[5])\n",
    "        results.append([[xmin, ymin, xmax - xmin, ymax - ymin], confidence, class_id])\n",
    "\n",
    "    # Update DeepSort tracker with detections\n",
    "    tracks = tracker.update_tracks(results, frame=frame)\n",
    "\n",
    "    for track in tracks:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "\n",
    "        track_id = track.track_id\n",
    "        ltrb = track.to_ltrb()\n",
    "        xmin, ymin, xmax, ymax = int(ltrb[0]), int(ltrb[1]), int(ltrb[2]), int(ltrb[3])\n",
    "\n",
    "        # Crop image of tracked person\n",
    "        cropped_image = frame[ymin:ymax, xmin:xmax]\n",
    "        os.makedirs(f\"tracked_images/{track_id}\", exist_ok=True)\n",
    "        cv.imshow(f\"tracked_images/{track_id}/frame_{start.timestamp()}.jpg\", cropped_image)\n",
    "\n",
    "        # Perform pose estimation\n",
    "        pose_frame = poseDetector(cropped_image)\n",
    "\n",
    "        # Overlay pose on original frame\n",
    "        frame[ymin:ymax, xmin:xmax] = pose_frame\n",
    "\n",
    "        # Draw bounding box and track ID\n",
    "        cv.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "        cv.rectangle(frame, (xmin, ymin - 20), (xmin + 20, ymin), (0, 255, 0), -1)\n",
    "        cv.putText(frame, str(track_id), (xmin + 5, ymin - 8), cv.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "    # Calculate and display FPS\n",
    "    end = datetime.datetime.now()\n",
    "    print(f\"Time to process 1 frame: {(end - start).total_seconds() * 1000:.0f} milliseconds\")\n",
    "    fps = f\"FPS: {1 / (end - start).total_seconds():.2f}\"\n",
    "    cv.putText(frame, fps, (50, 50), cv.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 8)\n",
    "\n",
    "    writer.write(frame)\n",
    "    if cv.waitKey(1) == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "video_cap.release()\n",
    "writer.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
